# Router.py: LangGraph Orchestrator for multi-agent trading system.
# - Defines workflow, node connections, and routing logic
from __future__ import annotations

import json, os
from typing import List, Dict, Any
import re

from dotenv import load_dotenv
from openai import OpenAI
from pydantic import BaseModel

from langchain_openai import ChatOpenAI
from langchain.tools import tool
from langgraph.graph import StateGraph, MessagesState, END
from langgraph.prebuilt import ToolNode

from .specialist_agents import (
    FinancialSpecialistAgent, NewsSpecialistAgent, TechnicalAnalysisAgent, MacroEconomicAgent, IndustrySectorAgent
)
from .strategy_agents import (
    MarketRegimeAgent, StrategySelectionAgent, SignalGenerationAgent, PortfolioConstructionAgent, RiskManagementAgent
)
from .decision_agent import DecisionAgent
from .schemas.models import MarketDataInput, TradingDecisionOutput

from AIChat.specialist_agents import FinancialAgent, NewsAgent, TechnicalAgent, MacroAgent, SectorAgent, OtherAgent
from AIChat.strategy_agents import StrategyAgent
from AIChat.decision_agent import DecisionAgent
import openai

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0. í™˜ê²½ ë³€ìˆ˜
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not (OPENAI_API_KEY and OPENAI_API_KEY.startswith("sk-")):
    raise ValueError("âŒ ìœ íš¨í•œ OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. ToolCall ëª¨ë¸
class ToolCall(BaseModel):
    name: str
    arguments: Dict[str, Any]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. Router (í•„ìš” ì‹œ ì‚¬ìš©)
class Router:
    """OpenAI í•¨ìˆ˜-ì½œë¡œ ì–´ë–¤ íˆ´ì„ ì“¸ì§€ ê²°ì •í•˜ëŠ” ë¼ìš°í„°"""
    def __init__(
        self,
        tool_specs: List[Dict[str, Any]],
        *,
        model: str = "gpt-4o-mini",
        api_key: str | None = None,
        system_prompt: str | None = None,
    ):
        self.tool_specs = tool_specs
        self.client = OpenAI(api_key=api_key or OPENAI_API_KEY)
        self.model = model
        self.system_prompt = system_prompt or (
            "You are a router that decides which tools the assistant should call."
        )

    def route(self, query: str) -> List[ToolCall]:
        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": query},
        ]
        resp = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            tools=self.tool_specs,
            temperature=0,
        )
        calls = resp.choices[0].message.tool_calls or []
        out: List[ToolCall] = []
        for tc in calls:
            try:
                out.append(ToolCall(name=tc.function.name,
                                    arguments=json.loads(tc.function.arguments)))
            except Exception:
                pass
        return out

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. íˆ´ ì •ì˜
@tool
def web_search(query: str, k: int = 5) -> str:
    """ì¸í„°ë„· ë‰´ìŠ¤/ì •ë³´ ê²€ìƒ‰"""
    from tool.newsAPI import GNewsClient  # local import
    return GNewsClient().get(keyword=query, max_results=k)

@tool
def financial_statements(ticker: str, limit: int = 3) -> str:
    """ì¢…ëª© ì¬ë¬´ì œí‘œ ì¡°íšŒ"""
    from tool.financial_statements import IncomeStatementClient
    data = IncomeStatementClient().get(ticker, limit)
    return f"{ticker}: {data}"

TOOLS = [web_search, financial_statements]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. LLM (íˆ´ ë°”ì¸ë”©)
llm = ChatOpenAI(
    model="gpt-4o-mini",
    api_key=OPENAI_API_KEY,
    temperature=0,
)
llm_with_tools = llm.bind_tools(TOOLS)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. LangGraph ì›Œí¬í”Œë¡œ
def should_continue(state: MessagesState):
    """ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ì— tool_calls ê°€ ìˆìœ¼ë©´ íˆ´ ì‹¤í–‰ ë‹¨ê³„ë¡œ"""
    last = state["messages"][-1]
    return "tools" if getattr(last, "tool_calls", None) else END

def call_model(state: MessagesState):
    msgs = state["messages"]
    resp = llm_with_tools.invoke(msgs)
    return {"messages": [resp]}

def build_workflow():
    builder = StateGraph(MessagesState)
    tool_node = ToolNode(TOOLS)                      # â˜… agent ì¸ì ì—†ìŒ :contentReference[oaicite:0]{index=0}
    builder.add_node("call_model", call_model)
    builder.add_node("tools", tool_node)

    from langgraph.graph import START
    builder.add_edge(START, "call_model")
    builder.add_conditional_edges("call_model", should_continue, ["tools", END])
    builder.add_edge("tools", "call_model")

    return builder.compile()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6. CLI
if __name__ == "__main__":
    print("ğŸ”§ LangGraph Tool Router CLI (Ctrl-C to exit)")
    graph = build_workflow()

    try:
        while True:
            q = input("\nQuestion > ").strip()
            if not q:
                continue
            result = graph.invoke({"messages": [{"role": "user", "content": q}]})
            for m in result["messages"]:
                print("â†’", getattr(m, "content", m))
    except (EOFError, KeyboardInterrupt):
        print("\nì¢…ë£Œí•©ë‹ˆë‹¤.")

class TradingOrchestrator:
    def __init__(self):
        self.financial_agent = FinancialAgent()
        self.news_agent = NewsAgent()
        self.technical_agent = TechnicalAgent()
        self.macro_agent = MacroAgent()
        self.sector_agent = SectorAgent()
        self.other_agent = OtherAgent()
        self.strategy_agent = StrategyAgent()
        self.decision_agent = DecisionAgent()
        self.llm_client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    def normalize_company_name(self, name: str) -> str:
        # ì†Œë¬¸ì ë³€í™˜, íŠ¹ìˆ˜ë¬¸ì/ê³µë°± ì œê±°
        return re.sub(r"[^ê°€-í£a-zA-Z0-9]", "", name.lower())

    def parse_input(self, user_input: str) -> dict:
        norm_name = self.normalize_company_name(user_input)
        ticker = None
        # 1. yahooqueryë¡œ í•œê¸€/ì˜ë¬¸/í˜¼í•© ì…ë ¥ ë°”ë¡œ ê²€ìƒ‰
        try:
            from yahooquery import search
            result = search(user_input)
            quotes = result.get('quotes', [])
            if quotes:
                ticker = quotes[0].get('symbol')
        except Exception:
            pass
        # 2. yahooquery ì‹¤íŒ¨ì‹œ LLMìœ¼ë¡œ ì˜ë¬¸ëª… ë³€í™˜ í›„ ì¬ê²€ìƒ‰
        if not ticker:
            try:
                import openai
                client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
                prompt = f"'{user_input}'ë¼ëŠ” í•œê¸€ ê¸°ì—…ëª…ì„ ì˜ë¬¸ ê³µì‹ ê¸°ì—…ëª…ìœ¼ë¡œ ë³€í™˜í•´ì¤˜. (ì˜ˆ: 'ì‚¼ì„±ì „ì'â†’'Samsung Electronics', 'ì—”ë¹„ë””ì•„'â†’'Nvidia')"
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": prompt}]
                )
                en_name = response.choices[0].message.content.strip()
                # ì˜ë¬¸ëª…ìœ¼ë¡œ yahooquery ì¬ê²€ìƒ‰
                from yahooquery import search
                result = search(en_name)
                quotes = result.get('quotes', [])
                if quotes:
                    ticker = quotes[0].get('symbol')
            except Exception:
                pass
        return {"ticker": ticker, "raw": user_input}

    def run(self, user_input: str) -> str:
        parsed = self.parse_input(user_input)
        # 1. Specialist/Strategy Agents í˜¸ì¶œ
        fin_data = self.financial_agent.get(parsed)
        news = self.news_agent.get(parsed)
        tech = self.technical_agent.get(parsed)
        macro = self.macro_agent.get(parsed)
        sector = self.sector_agent.get(parsed)
        other = self.other_agent.get(parsed)
        # 2. ì „ëµ/ì‹œê·¸ë„/í¬íŠ¸í´ë¦¬ì˜¤/ë¦¬ìŠ¤í¬ ê´€ë¦¬
        strategy = self.strategy_agent.get(parsed, fin_data, tech, macro, sector)
        # 3. í†µí•© ì˜ì‚¬ê²°ì • Agent
        decision = self.decision_agent.get(
            fin_data, news, tech, macro, sector, other, strategy
        )
        # 4. LLM í”„ë¡¬í”„íŠ¸ë¡œ ìì—°ì–´ ì„¤ëª… ìƒì„±
        llm_prompt = self.build_llm_prompt(user_input, fin_data, news, tech, macro, sector, other, strategy, decision)
        response = self.llm_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "system", "content": "ì•„ë˜ëŠ” ë©€í‹°ì—ì´ì „íŠ¸ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œì˜ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ìš”ì•½í•´ ì£¼ì„¸ìš”."},
                      {"role": "user", "content": llm_prompt}]
        )
        answer = response.choices[0].message.content.strip()
        return answer

    def build_llm_prompt(self, user_input, fin_data, news, tech, macro, sector, other, strategy, decision):
        """
        LLMì— ë„˜ê¸¸ í”„ë¡¬í”„íŠ¸ë¥¼ í†µí•©ì ìœ¼ë¡œ ìƒì„±
        """
        prompt = f"""
[ì‚¬ìš©ì ì§ˆë¬¸]
{user_input}

[ì¬ë¬´ ë°ì´í„°]
{fin_data}

[ë‰´ìŠ¤]
{news}

[ê¸°ìˆ ì  ë¶„ì„]
{tech}

[ê±°ì‹œê²½ì œ]
{macro}

[ì‚°ì—…/ì„¹í„°]
{sector}

[ê¸°íƒ€]
{other}

[ì „ëµ/ì‹œê·¸ë„/í¬íŠ¸í´ë¦¬ì˜¤/ë¦¬ìŠ¤í¬ ê´€ë¦¬]
{strategy}

[í†µí•© ì˜ì‚¬ê²°ì •]
{decision}

ìœ„ì˜ ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì‰½ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”.
"""
        return prompt